{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7d6f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\n",
      "Collecting numpy\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/a3/dd/4b822569d6b96c39d1215dbae0582fd99954dcbcf0c1a13c61783feaca3f/numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.9 MB 35.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.9 MB 62.0 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 47.7 MB/s eta 0:00:00\n",
      "Collecting gensim\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/cd/4a/f07e2f255aedd6bb4bd0ae420a465f228a4a91bc78ac359216ea20557be6/gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "     ------------------------- ------------- 15.7/24.0 MB 82.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 24.0/24.0 MB 58.5 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/19/77/538f202862b9183f54108557bfda67e17603fc560c384559e769321c9d92/numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     --------------------------------------  15.7/15.8 MB 76.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.8/15.8 MB 55.3 MB/s eta 0:00:00\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/12/30/df7a8fcc08f9b4a83f5f27cfaaa7d43f9a2d2ad0b6562cced433e5b04e31/scipy-1.13.1-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "     ----------- --------------------------- 13.4/46.2 MB 70.1 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 27.3/46.2 MB 66.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 40.4/46.2 MB 65.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  46.1/46.2 MB 65.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 46.2/46.2 MB 52.5 MB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/7a/18/9a8d9f01957aa1f8bbc5676d54c2e33102d247e146c1a3679d3bd5cc2e3a/smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/72/6a/c5a83e8f61aec1e1aeef939807602fb880e5872371e95df2137142f5c58e/wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "\n",
      "   ---------------------------------------- 0/5 [wrapt]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   ---------------- ----------------------- 2/5 [smart-open]\n",
      "   ---------------- ----------------------- 2/5 [smart-open]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   ---------------------------------------- 5/5 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad843e3-ac0b-4266-9eba-52eba01d739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CMH\\.conda\\envs\\TransNeXt\\lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Building prefix dict from the default dictionary ...\n",
      "2025-06-25 19:11:48,917 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CMH\\AppData\\Local\\Temp\\jieba.cache\n",
      "2025-06-25 19:11:48,921 : DEBUG : Loading model from cache C:\\Users\\CMH\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.828 seconds.\n",
      "2025-06-25 19:11:49,749 : DEBUG : Loading model cost 0.828 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2025-06-25 19:11:49,752 : DEBUG : Prefix dict has been built successfully.\n",
      "2025-06-25 19:11:51,771 : INFO : collecting all words and their counts\n",
      "2025-06-25 19:11:51,772 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-06-25 19:11:51,819 : INFO : collected 12099 word types from a corpus of 188848 raw words and 10000 sentences\n",
      "2025-06-25 19:11:51,820 : INFO : Creating a fresh vocabulary\n",
      "2025-06-25 19:11:51,843 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 4028 unique words (33.29% of original 12099, drops 8071)', 'datetime': '2025-06-25T19:11:51.843233', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-06-25 19:11:51,845 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 179103 word corpus (94.84% of original 188848, drops 9745)', 'datetime': '2025-06-25T19:11:51.845236', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-06-25 19:11:51,871 : INFO : deleting the raw counts dictionary of 12099 items\n",
      "2025-06-25 19:11:51,874 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2025-06-25 19:11:51,874 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 127397.55238210877 word corpus (71.1%% of prior 179103)', 'datetime': '2025-06-25T19:11:51.874595', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-06-25 19:11:51,917 : INFO : estimated required memory for 4028 words and 300 dimensions: 11681200 bytes\n",
      "2025-06-25 19:11:51,918 : INFO : resetting layer weights\n",
      "2025-06-25 19:11:51,923 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-25T19:11:51.923688', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "2025-06-25 19:11:51,925 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 4028 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-25T19:11:51.924691', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-06-25 19:11:52,313 : INFO : EPOCH 0: training on 188848 raw words (127440 effective words) took 0.4s, 338811 effective words/s\n",
      "2025-06-25 19:11:52,634 : INFO : EPOCH 1: training on 188848 raw words (127272 effective words) took 0.3s, 407690 effective words/s\n",
      "2025-06-25 19:11:52,972 : INFO : EPOCH 2: training on 188848 raw words (127516 effective words) took 0.3s, 388176 effective words/s\n",
      "2025-06-25 19:11:53,325 : INFO : EPOCH 3: training on 188848 raw words (127361 effective words) took 0.3s, 370397 effective words/s\n",
      "2025-06-25 19:11:53,664 : INFO : EPOCH 4: training on 188848 raw words (127361 effective words) took 0.3s, 391235 effective words/s\n",
      "2025-06-25 19:11:53,665 : INFO : Word2Vec lifecycle event {'msg': 'training on 944240 raw words (636950 effective words) took 1.7s, 366617 effective words/s', 'datetime': '2025-06-25T19:11:53.665131', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-06-25 19:11:53,665 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4028, vector_size=300, alpha=0.025>', 'datetime': '2025-06-25T19:11:53.665131', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-06-25 19:11:53,666 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec_skipgram.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-25T19:11:53.666136', 'gensim': '4.3.3', 'python': '3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-06-25 19:11:53,668 : INFO : not storing attribute cum_table\n",
      "2025-06-25 19:11:53,682 : INFO : saved word2vec_skipgram.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 模型参数 =====\n",
      "模型架构: Skip-Gram\n",
      "词表大小: 4028\n",
      "训练总词数: 188848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 词向量训练（Skip-Gram模式）\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import logging  # 添加日志记录\n",
    "\n",
    "# 配置日志输出\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 1. 数据预处理\n",
    "def preprocess_text(text):\n",
    "    \"\"\"文本清洗和分词处理\"\"\"\n",
    "    # 去除标点符号（扩展更全的标点集合）\n",
    "    punctuation = \"，。！？、；：“”‘’【】（）《》~@#￥%……&*\"\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, \"\")\n",
    "    return jieba.lcut(text)\n",
    "\n",
    "# 读入训练集文件\n",
    "data = pd.read_csv('train.csv')\n",
    "corpus = [preprocess_text(str(comment)) for comment in data['comment'].values]\n",
    "\n",
    "# 2. Skip-Gram模型训练\n",
    "model = Word2Vec(\n",
    "    corpus,\n",
    "    sg=1,  # 关键修改：sg=1表示使用Skip-Gram（默认CBOW是sg=0）\n",
    "    vector_size=300,  # 词向量维度\n",
    "    window=5,        # 上下文窗口大小（Skip-Gram通常用更大窗口）\n",
    "    min_count=3,     # 忽略低频词\n",
    "    workers=4,       # 并行线程数\n",
    "    negative=5,      # 负采样数（Skip-Gram推荐5-20）\n",
    "    hs=0,            # 禁用层次softmax（与negative采样二选一）\n",
    "    alpha=0.025,     # 初始学习率\n",
    "    min_alpha=0.0001 # 最小学习率\n",
    ")\n",
    "\n",
    "# 3. 模型保存与加载\n",
    "model.save(\"word2vec_skipgram.model\")  # 保存模型\n",
    "# model = Word2Vec.load(\"word2vec_skipgram.model\")  # 加载模型\n",
    "\n",
    "# 4. 模型验证\n",
    "print('\\n===== 模型参数 =====')\n",
    "print(f\"模型架构: {'Skip-Gram' if model.sg else 'CBOW'}\")\n",
    "print(f\"词表大小: {len(model.wv)}\")\n",
    "print(f\"训练总词数: {model.corpus_total_words}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8988a179-58d7-4c86-bfbb-d39c95ebdf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与'点赞'最相似的词：[('气氛', 0.9861142635345459), ('人超', 0.9856061339378357), ('特', 0.9842628836631775)]\n",
      "与'不错'最相似的词：[('好极了', 0.9139845967292786), ('挺不错', 0.9026724100112915), ('纯正', 0.8975269198417664)]\n",
      "与'难吃'最相似的词：[('垃圾', 0.8909440040588379), ('咸', 0.8723955154418945), ('实在', 0.8503879904747009)]\n",
      "与'推荐'最相似的词：[('值得', 0.8977064490318298), ('一去', 0.8875811100006104), ('一试', 0.8784179091453552)]\n",
      "与'地道'最相似的词：[('正', 0.9781695604324341), ('很赞', 0.9704442620277405), ('依旧', 0.9675837755203247)]\n",
      "\n",
      "'地道'的词向量（前10维）:\n",
      "[-0.03942199  0.01611122 -0.01001185  0.04299872 -0.06971505 -0.05957232\n",
      "  0.14781     0.40237567 -0.09764312 -0.11671848]\n"
     ]
    }
   ],
   "source": [
    "# 语义相似度查询\n",
    "test_words = ['点赞', '不错', '难吃', '推荐', '地道']\n",
    "for word in test_words:\n",
    "    if word in model.wv:\n",
    "        print(f\"与'{word}'最相似的词：{model.wv.most_similar(word, topn=3)}\")\n",
    "\n",
    "# 向量获取示例\n",
    "if '地道' in model.wv:\n",
    "    print(f\"\\n'地道'的词向量（前10维）:\\n{model.wv['地道'][:10]}\")\n",
    "else:\n",
    "    print(\"\\n警告：'地道'不在词表中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47c61cc-8710-4eee-b846-2f81be9d6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'环境'的词向量（前5维）:\n",
      "[-0.14039193  0.07566755 -0.1379349   0.06719865 -0.07074745]\n",
      "词向量形状: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 检查并输出\"环境\"的词向量及形状\n",
    "if '环境' in model.wv:\n",
    "    env_vector = model.wv['环境']\n",
    "    print(f\"'环境'的词向量（前5维）:\\n{env_vector[:5]}\")\n",
    "    print(f\"词向量形状: {env_vector.shape}\")  # 应输出 (300,)\n",
    "else:\n",
    "    print(\"警告：'环境'不在词表中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a88d47-f5b1-4ac3-ab25-f9a6d92154a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "与'好吃'最相似的3个词:\n",
      "棒: 0.8560\n",
      "入味: 0.8390\n",
      "好看: 0.8320\n",
      "\n",
      "词语相似度:\n",
      "'好吃' vs '美味': 0.8133\n",
      "'好吃' vs '蟑螂': 0.2728\n"
     ]
    }
   ],
   "source": [
    "# 输出与\"好吃\"最相似的3个词\n",
    "if '好吃' in model.wv:\n",
    "    print(\"\\n与'好吃'最相似的3个词:\")\n",
    "    for word, similarity in model.wv.most_similar('好吃', topn=3):\n",
    "        print(f\"{word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"警告：'好吃'不在词表中\")\n",
    "\n",
    "# 计算词语相似度\n",
    "similarity_results = []\n",
    "for word in ['美味', '蟑螂']:\n",
    "    if '好吃' in model.wv and word in model.wv:\n",
    "        sim = model.wv.similarity('好吃', word)\n",
    "        similarity_results.append((word, sim))\n",
    "    else:\n",
    "        print(f\"警告：'{word}'不在词表中\")\n",
    "\n",
    "print(\"\\n词语相似度:\")\n",
    "for word, sim in similarity_results:\n",
    "    print(f\"'好吃' vs '{word}': {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9eceec0-25f5-4f19-bf5b-bea9dc9e2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "向量运算 '餐厅 + 聚会 - 安静' ≈ '酒店' (相似度: 0.9638)\n"
     ]
    }
   ],
   "source": [
    "# 向量类比计算\n",
    "if all(word in model.wv for word in ['餐厅', '聚会', '安静']):\n",
    "    result = model.wv.most_similar(\n",
    "        positive=['餐厅', '聚会'],\n",
    "        negative=['安静'],\n",
    "        topn=1\n",
    "    )\n",
    "    print(f\"\\n向量运算 '餐厅 + 聚会 - 安静' ≈ '{result[0][0]}' (相似度: {result[0][1]:.4f})\")\n",
    "else:\n",
    "    print(\"警告：计算所需的词未全部存在于词表中\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransNeXt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
